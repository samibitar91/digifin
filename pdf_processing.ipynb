{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|█| 45/45 [00:19<00:00,  2.28file/s, file=Konto_1302319718-Auszug_2024_0010.PDF\n"
     ]
    }
   ],
   "source": [
    "# List of keywords\n",
    "keywords = [\n",
    "    'Abrechnung',\n",
    "    'Bargeldaus',\n",
    "    'Bargeldauszahlung',\n",
    "    'Bargeldein',\n",
    "    'Bargeldeinzahlung',\n",
    "    'Entgeltabrechnung',\n",
    "    'Entgelte',\n",
    "    'Geldaus.',\n",
    "    'Gut. Überw.',\n",
    "    'Gutschr.',\n",
    "    'GutschriftÜberweisung',\n",
    "    'Kartenzahlung',\n",
    "    'Kontostand',\n",
    "    'Lastschrift',\n",
    "    'Überweisung',\n",
    "    'Überweisung Echtzeit',\n",
    "    'Überweisung online'\n",
    "]\n",
    "\n",
    "\n",
    "def extract_transactions(pdf_path, keywords):\n",
    "    transactions = []  # List to hold all rows\n",
    "    columns = []  # List to store column names\n",
    "    with pdfplumber.open(pdf_path) as pdf:  # Open the PDF\n",
    "        for page_number, page in enumerate(pdf.pages, start=1):  # Iterate through pages\n",
    "            tables = page.extract_tables()  # Extract all tables on the page\n",
    "            \n",
    "            for table_index, table in enumerate(tables):  # Iterate through each table\n",
    "                if page_number == 1:  # If it's the first page\n",
    "                    columns = table[0]  # Extract columns from the first table\n",
    "                    table = table[1:]  # Skip the first row in the first table (header row)\n",
    "                else:\n",
    "                    table = table[1:]  # Skip the first row (column names) for subsequent tables\n",
    "\n",
    "                # Process the second row (data) in the table\n",
    "                if table:\n",
    "                    combined_data = table[0]  # Second row of the table\n",
    "                    # Step 1: Replace all \\n with spaces except for ones directly before a keyword\n",
    "                    try:\n",
    "                        # Find the index of the \"Erläuterung\" column\n",
    "                        description_index = columns.index(\"Erläuterung\")\n",
    "                    except ValueError:\n",
    "                        # Raise an error if the column is not found\n",
    "                        raise ValueError(\"Error: The column 'Erläuterung' was not found in the header.\")\n",
    "                    \n",
    "                    # Step 2: Remove \\n from Erlaueterung list except before keyword\n",
    "                    desc = table[0][description_index]\n",
    "                    processed_desc = \"\".join(\n",
    "                        f\"\\n{line}\" if any(line.startswith(keyword) for keyword in keywords) else \n",
    "                        f\" {line}\"\n",
    "                        for line in desc.split(\"\\n\")\n",
    "                    ).strip()\n",
    "                    table[0][description_index] = processed_desc\n",
    "\n",
    "                    # Step 3: Split each string in combined_data by '\\n'\n",
    "                    split_cells = [cell.split(\"\\n\") for cell in combined_data]\n",
    "                    # Access the description list using the dynamically determined index\n",
    "                    description_list = split_cells[description_index]\n",
    "\n",
    "                    # Process all columns before \"Erläuterung\"\n",
    "                    for col_idx in range(description_index):\n",
    "                        column_data = split_cells[col_idx]  # Get the current column's data\n",
    "\n",
    "                        # Check if 'Kontostand' is found in the first or last element of the description list\n",
    "                        if \"Kontostand\" in description_list[0]:\n",
    "                            column_data.insert(0, column_data[0])  # Add a copy of the first value\n",
    "                        if \"Kontostand\" in description_list[-1]:\n",
    "                            column_data.append(column_data[-1])  # Add a copy of the last value\n",
    "\n",
    "                        # Update the split_cells with the modified column data\n",
    "                        split_cells[col_idx] = column_data\n",
    "\n",
    "                    # Step 4: Transpose the lists to group by rows\n",
    "                    zipped_rows = zip(*split_cells)\n",
    "\n",
    "                    # Step 5: Convert zipped rows into a list for final use\n",
    "                    split_rows = list(zipped_rows)\n",
    "\n",
    "                    transactions.extend(split_rows)  # Append all split rows to transactions\n",
    "\n",
    "    return pd.DataFrame(transactions, columns=columns)  # Return both columns and data as a dataframe  \n",
    "\n",
    "def process_pdfs_in_folder(folder_path):\n",
    "    dataframes = []  # List to store DataFrames\n",
    "    folder = Path(folder_path)  # Create a Path object for the folder\n",
    "    pdf_files = list(folder.glob(\"*.pdf\"))  # List all PDFs in the folder that match the pattern\n",
    "\n",
    "    # Filter out only PDFs with \"Konto\" and \"Auszug\" in the filename\n",
    "    pdf_files = [file for file in pdf_files if \"Konto\" in file.name and \"Auszug\" in file.name]\n",
    "\n",
    "    # Display progress bar using tqdm, with no extra new lines\n",
    "    with tqdm(total=len(pdf_files), desc=\"Processing PDFs\", unit=\"file\", ncols=100, leave=True) as pbar:\n",
    "        for file_path in pdf_files:\n",
    "            try:\n",
    "                df1 = extract_transactions(file_path, keywords)  # Extract transactions\n",
    "                dataframes.append(df1)  # Add the DataFrame to the list\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path.name}: {e}\")\n",
    "            pbar.set_postfix({\"file\": file_path.name})  # Display current file being processed\n",
    "            pbar.update(1)  # Update progress bar by one step\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"D:/Sparkasse-Duisburg-Kontoauszuege\"  # Replace with the path to your folder containing PDFs\n",
    "\n",
    "all_dataframes = process_pdfs_in_folder(folder_path)\n",
    "all_dataframes[9].to_csv(f'{folder_path}/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the locale to German (Germany) to handle the German date and currency format\n",
    "locale.setlocale(locale.LC_TIME, 'de_DE')  # For date parsing\n",
    "locale.setlocale(locale.LC_NUMERIC, 'de_DE')  # For numeric parsing\n",
    "\n",
    "def process_dataframes(in_dataframes):\n",
    "    processed_dfs = []\n",
    "\n",
    "    # Iterate through the input DataFrames\n",
    "    for df2 in in_dataframes:\n",
    "        # Step 1: Remove \"Wert\" column if it exists\n",
    "        if 'Wert' in df2.columns:\n",
    "            df2 = df2.drop(columns=['Wert'])\n",
    "\n",
    "        # Step 2: Convert 'Datum' column to datetime, ensuring no empty spaces and raise error on failure\n",
    "        if 'Datum' in df2.columns:\n",
    "            df2['Datum'] = df2['Datum'].astype(str)  # Ensure all values are strings\n",
    "            \n",
    "            # Remove any spaces in the 'Datum' string\n",
    "            df2['Datum'] = df2['Datum'].str.replace(' ', '', regex=False)\n",
    "            \n",
    "            # Try to parse the 'Datum' column, and raise an error if parsing fails\n",
    "            try:\n",
    "                df2['Datum'] = pd.to_datetime(df2['Datum'], errors='raise', dayfirst=True)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error parsing 'Datum' values: {e}\")\n",
    "\n",
    "        # Step 3: Convert 'Betrag EUR' to numeric format, ensuring correct parsing, raise error on failure\n",
    "        if 'Betrag EUR' in df2.columns:\n",
    "            df2['Betrag EUR'] = df2['Betrag EUR'].astype(str)  # Convert all values to strings\n",
    "            \n",
    "            # Try to parse the 'Betrag EUR' column, and raise an error if parsing fails\n",
    "            try:\n",
    "                df2['Betrag EUR'] = df2['Betrag EUR'].apply(\n",
    "                    lambda x: locale.atof(f\"{x[-1]}{x[:-1]}\" if x[-1] in '+-' else x)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error parsing 'Betrag EUR' values: {e}\")\n",
    "\n",
    "        # Step 4: Append the processed DataFrame to the result list\n",
    "        processed_dfs.append(df2)\n",
    "\n",
    "    # Combine all processed DataFrames into one\n",
    "    combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "\n",
    "    # Step 5: Sort combined DataFrame by 'Datum' (earliest first)\n",
    "    combined_df = combined_df.sort_values(by='Datum', ascending=True)\n",
    "\n",
    "    # Initialize 'Saldo' column to None\n",
    "    combined_df['Saldo'] = None\n",
    "\n",
    "    # Step 6: Initialize current_balance with the first row's Betrag EUR value\n",
    "    current_balance = combined_df.iloc[0]['Betrag EUR']\n",
    "    combined_df.at[0, 'Saldo'] = current_balance\n",
    "\n",
    "\n",
    "    # Step 7: Iterate starting from the second row\n",
    "    for index, row in combined_df.iloc[1:].iterrows():\n",
    "        if 'Kontostand' in row['Erläuterung']:\n",
    "            # For 'Kontostand' rows, copy the previous balance (no accumulation)\n",
    "            combined_df.at[index, 'Saldo'] = current_balance\n",
    "        else:\n",
    "            # For transaction rows, first set Saldo to the current balance, then update it\n",
    "            current_balance += row['Betrag EUR']  # Update the balance after the 'Saldo' is assigned\n",
    "            combined_df.at[index, 'Saldo'] = current_balance\n",
    "\n",
    "    # Round the 'Saldo' column to two decimal places\n",
    "    combined_df['Saldo'] = combined_df['Saldo'].round(2)\n",
    "\n",
    "    # Step 8: Save the combined DataFrame as a CSV file\n",
    "    folder_path = \"D:/Sparkasse-Duisburg-Kontoauszuege\"  # Modify this path to your folder path\n",
    "    combined_df.to_csv(f'{folder_path}/transactions.csv', index=False)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Example: Process all dataframes and generate the combined dataframe\n",
    "all_transactions = process_dataframes(all_dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datum          datetime64[ns]\n",
      "Erläuterung            object\n",
      "Betrag EUR            float64\n",
      "Saldo                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(all_transactions.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
